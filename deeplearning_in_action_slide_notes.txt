-- open files:

1)
./convnet_demo_convolution.html

2)
./convnetjs_demo_classify2d.html

3)
cd /home/key/code/python/tensorflow-playground
npm run serve



Action
========================================================

- autonomous driving: where are the others, how are they moving/what are they doing, where am I, how are the weather conditions, how do I get to ...?
  -> deep neural networks used for object recognition and localization, deep reinforcement learning used for motion planning

- machine translation: as you type, Google updates the translation. Also, Google does language detection, and updates the guess at every step. How does this work - language comes in as a sequence, how do I keep track of the elements I've already seen, and how do I weigh the new input against the old, and how is the translation generated?
  -> again, deep NNs are responsible for a recent big improvement in performance
  
- medical diagnosis: example: detection of skin cancer: CNNs performing on par with human experts - opportunities for more large-scale prevention, e.g. using smartphone app

- pharmacology: develop new drugs - normally developing new pharmacological products is extremely costly and  takes very long, so if this could be sped up enormous savings would result
  -> generative adversarial neural networks

- AlphaGo: March 2016, AlphaGo wins 4/5 matches against Lee Sedol - Go substantially more difficult than chess - AI win predicted to take considerably longer by experts
  -> combination of 2 deep neural networks (the policy network suggests the move, the value network evaluates the position) - first the policy network was trained on input from human experts, then both networks were further evolved using reinforcement learning
  -> talk shortly about reinforcement learning later
  
- stock market prediction: often when people try to predict the stock market they use numerical data - however, those numerical data mostly are available "after the fact". Using textual data (newspaper articles etc.) is more complex and you need to be able to handle sequences (of words)
  -> again, a certain type of deep NN is especially suited for handling temporal data, we'll see that later
  
- predicting the weather: The Weather Company, acquired by IBM, provides extremely localized, short time weather forecasts, as well as long-term seasonal predictions. They are said to use deep learning algorithms for that. 



So what is a neural network?
========================================================

make it clear that the weights have to be learned! (while inputs are fixed)


Prototype of a neuron: the perceptron (Rosenblatt, 1958)
========================================================

- compute linear combination of inputs
- return +1 if result is positive, -1 if result is negative



ConvNetJS Demo
========================================================

explain the TASK!!

1. SIMPLE data, shallow network

-> task cannot be solved

layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});


2. SIMPLE data, 1 hidden layer with tanh activation

-> now it works!

layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});


3. SIMPLE data, change learning rate (0.001)

-> takes much longer

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.001, momentum:0.1, batch_size:10, l2_decay:0.001});


4. SIMPLE data, change learning rate (0.5)

-> extremely quick in this case, but can also not converge

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.5, momentum:0.1, batch_size:10, l2_decay:0.001});


5. SIMPLE data, change activation function to relu

-> seems slower

layer_defs.push({type:'fc', num_neurons:2, activation: 'relu'});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});


6. CIRCLE data, still 1 hidden layer with relu or tanh activation

-> does not work


7. CIRCLE data, change number of neurons in hidden unit to 3

-> works (and superquick!)

layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});


8. SPIRAL data, still with tanh activation and 3 neurons

do you think this will work?
although you don't see, it keeps trying on and on... (show top)


9. SPIRAL data, add another hidden layer with 3 neurons

-> gets real "upset"

layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});
layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});


10. SPIRAL data, more neurons in hidden layers

-> this does it!




TensorFlow playground Demo
========================================================

cd /home/key/code/python/tensorflow-playground
[npm run build]
npm run serve

1. Gaussian data

- 0 hidden layers
- just 1 input
- noise 0
- TRAIN

-> loss is nearly 0, as the data don't overlap on any axis!

2. Gaussian data

- change noise
- TRAIN
- with higher noise, 1 neuron cannot get it right any more


3. Gaussian data

- add 2nd neuron
- TRAIN
- now still have a separating line, but the line need not be vertical or horizontal any more


4. exclusive OR

- remove noise again and try with our 2 neurons
- TRAIN
- whatever we do, loss stays at 0.5


5. exclusive OR

- add hidden layer with 2 neurons
- TRAIN
- gets better but not good


6. exclusive OR

- add third neuron to hidden layer
- TRAIN
- already MUCH better!


-> stopping here - you can comfortably play around with learning rate, activation, regularization...


Quantifying error: Loss functions
========================================================

http://datascience.stackexchange.com/questions/9302/the-cross-entropy-error-function-in-neural-networks


Localization
========================================================

2 ways:
- slide window over image
- or predict bounding box coordinates (regression)


Object Detection
========================================================

done by binary mask regression for each object type combined with predicting the bounding box coordinates


Gimp demo
========================================================

blur: set divisor=9!


