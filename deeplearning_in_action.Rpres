```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE)
#opts_chunk$set(out.width='750px', dpi=200)
```
<style>
.reveal table td{
    border: 0;
}
.reveal table {
    border: 0;
}
.small-code pre code {
  font-size: 1em;
}
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}
.footer {
    position: fixed; 
    top: 90%;
    text-align:right; 
    width:90%;
    margin-top:-150px;
}
.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
</style>


Deep Learning in Action
========================================================
autosize: true
width: 1440
incremental:true 

What brings you here?
========================================================

Let me guess...


<table>
<tr>
<td><img src='self_driving_cars.png' width='200px' /></td><td><img src='translate.png' width='200px'/></td><td><img src='skincancer.png' width='200px'/></td>
</tr>
<tr>
<td><img src='go.png' width='200px' /></td><td><img src='stock.png' width='200px'/></td><td><img src='weather.png' width='200px'/></td>
</tr>
<tr><td>Image sources: [1],[3],[4],[5],[6]</td></tr>
</table>

<!-- 
- autonomous driving: where are the others, how are they moving/what are they doing, where am I, how are the weather conditions, how do I get to ...?
  -> deep neural networks used for object recognition and localization, deep reinforcement learning used for motion planning
  -> more upcoming

- machine translation: as you type, Google updates the translation. Also, Google does language detection, and updates the guess at every step. How does this work - language comes in as a sequence, how do I keep track of the elements I've already seen, and how do I weight the new input against the old, and how is the translation generated?
  -> again, deep NNs are responsible for a recent big improvement in performance
  -> more upcoming
  
- medical diagnosis: example: detection of skin cancer: CNNs performing on par with human experts - opportunities for more large-scale prevention, e.g. using smartphone app

- pharmacology: develop new drugs - normally developing new pharmacological products is extremely costly and  takes very long, so if this could be speeded up enormous savings would result
  -> generative adverserial neural networks

- AlphaGo: March 2016, AlphaGo wins 4/5 matches against Lee Sedol - Go substantially more difficult than chess - AI win predicted to take considerably longer by experts
  -> combination of 2 deep neural networks (the policy network suggests the move, the value network evaluates the position) - first the policy network was trained on input from human experts, then both networks were further evolved using reinforcement learning
  
- stock market prediction: often when people try to predict the stock market they use numerical data - however, those numerical data mostly are available "after the fact". Using textual data (newspaper articles etc.) is more complex and needs to be able to handle sequences (of words)
  -> again, a certain type of deep NN is especially suited for handling temporal data
  
- predicting the weather: The Weather Company, acquired by IBM, provides extremely localized, short time weather forecasts, as well as long-term seasonal predictions. They are said to use deep learning algorithms for that. 


Sources
========================================================
incremental:false

[1] <a href='http://selfdrivingcars.mit.edu/'>MIT 6.S094: Deep Learning for Self-Driving Cars Lecture Slides</a>

[3] <a href='http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html'>Esteva et al., Dermatologist-level classification of skin cancer with deep neural networks</a>

[4] <a href='https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol'>Wikipedia, AlphaGo versus Lee Sedol</a>

[5] <a href='www.sciedupress.com/journal/index.php/air/article/download/7720/5022'>Yoshihara et al., Leveraging temporal properties of news events for stock market prediction.</a>

[6] <a href='http://www.theweathercompany.com/newsroom/2017/01/23/seasonal-outlook-weather-company-predicts-unusually-mild-weather-early-february'</a> The Weather Company, Seasonal forecast</a>

[7] <a href= 'http://www.dddmag.com/news/2017/02/neural-network-learns-select-potential-anticancer-drugs'>Neural Network Learns to Select Potential Anticancer Drugs</a>

[8] <a href='https://research.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html'>Google Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning</a>

[9] <a href='http://www.theweathercompany.com/DeepThunder'>The Weather Company Launches Deep Thunder - the World’s Most Advanced Hyper-Local Weather Forecasting Model for Businesses</a>






So what is a neural network?
========================================================
pic tbd

https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html


Deep neural networks
========================================================
A deep representation is a composition of many functions

$x \xrightarrow{w_1} h_1 \xrightarrow{w_2} h_2 \xrightarrow{w_3} ... \xrightarrow{w_n} h_n \xrightarrow{w_{n+1}} y$


Backpropagation
========================================================
![optional caption text](backprop.png)

http://cs231n.github.io/optimization-2/

// If we anthropomorphize the circuit as wanting to output a higher value (which can help with intuition), then we can think of the circuit as “wanting” the output of the add gate to be lower (due to negative sign), and with a force of 4. To continue the recurrence and to chain the gradient, the add gate takes that gradient and multiplies it to all of the local gradients for its inputs (making the gradient on both x and y 1 * -4 = -4). 


Hard is easy, easy is hard
========================================================

![optional caption text](moravec.png)

MIT Course 6.S094:
Deep Learning for Self-Driving Cars


Convnetjs demo
========================================================

1. shallow network, simple data

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

2. deep network, simple data, 1 hidden layer with tanh activation

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

3. deep network, simple data, change learning rate (0.001)

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.001, momentum:0.1, batch_size:10, l2_decay:0.001});
```

4. deep network, simple data, change learning rate (0.5)

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.5, momentum:0.1, batch_size:10, l2_decay:0.001});
```

5. deep network, simple data, change activation function to relu

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:2, activation: 'relu'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

6. deep network, circle data, still 1 hidden layer with relu or tanh activation

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:2, activation: 'relu'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

7. deep network, circle data, change number of neurons in hidden unit to 3

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

8. deep network, spiral data, still with tanh activation and 3 neurons

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

9. deep network, spiral data, add another hidden layer with 3 neurons

```
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:2});
layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});
layer_defs.push({type:'fc', num_neurons:3, activation: 'tanh'});
layer_defs.push({type:'softmax', num_classes:2});

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01, momentum:0.1, batch_size:10, l2_decay:0.001});
```

10. deep network, spiral data, more neurons in hidden layers




Representation learning
========================================================
pics from pres



Why computer vision is hard
========================================================

![optional caption text](deformable_cat.png)


http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf


Tasks in computer vision
========================================================

![optional caption text](class_loc_dec_seg.png)

Source: CS231n (Stanford) lecture slides


Classification
========================================================

![optional caption text](classification.png)

A. Krizhevsky, I. Sutskever and G. Hinton, “ImageNet Classification with Deep Convolutional Neural Networks”, in Advances in Neural Information Processing Systems, 2012.

// output probability for each class

Localization
========================================================

![optional caption text](localization.png)

[1] Erhan D., Szegedy C., Toshev, A., and Anguelov, D., "Scalable Object Detection using Deep Neural Networks", The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014, pp. 2147-2154.

// slide window over image
// or predict bounding box coordinates (regression)


Object Detection
========================================================

![optional caption text](detection.png)

http://image-net.org/challenges/LSVRC/2014/

// = classifying and localizing multiple objects in an image 
// aka image recognition
// binary mask regression for each object type combined with predicting the bounding box coordinates


Segmentation
========================================================

![optional caption text](segmentation.png)

https://arxiv.org/pdf/1411.4038.pdf

//the network needs to predict a class value for each input pixel.


Semantic vs. Instance Segmentation
========================================================

![optional caption text](segmentation.png)

https://arxiv.org/pdf/1411.4038.pdf

@inproceedings{SilbermanCoverage:ECCV14,
  author    = {Nathan Silberman, David Sontag and Rob Fergus},
  title     = {Instance Segmentation of Indoor Scenes using a Coverage Loss},
  booktitle = {ECCV},
  year      = {2014}
}


Convnet visualization
========================================================

https://arxiv.org/pdf/1311.2901.pdf


RNN
========================================================

colah

LSTM "conveyor belt"


Word2Vec
========================================================




Linking images and language: image caption generation
========================================================

![optional caption text](image_captions.png)
![optional caption text](image_captions2.png)

http://cs.stanford.edu/people/karpathy/cvpr2015.pdf


Linking video and sound: adding audio to silent film
========================================================

![optional caption text](sound_generation.png)

https://arxiv.org/pdf/1512.08512.pdf











Reinforcement learning: Welcome to the humans
========================================================

![optional caption text](typesofml.png) 

Source: deep driving

![optional caption text](dopamine.png) 

Reinforcement learning: Welcome to the humans
========================================================

> David Silver, Google Deep Mind: _Reinforcement Learning: AI = RL_

> Takeaway from Supervised Learning:
Neural networks are great at memorization and not (yet)
great at reasoning.
Hope for Reinforcement Learning:
Brute-force propagation of outcomes to knowledge about
states and actions. This is a kind of brute-force “reasoning”.
MIT DD


Delayed reward
========================================================

If I get a reward many many actions later, how do I find out what I'm getting the reward _for_?


Reinforcement learning
========================================================

![optional caption text](robot.png)

MIT



Deep reinforcement learning
========================================================

![optional caption text](dqn.png) 

http://www.nature.com/articles/nature16961.epdf?referrer_access_token=S7uXxNIroKd-0ITVLIW9mdRgN0jAjWel9jnR3ZoTv0OivKk3lXs6SxMz535byYwHnl5-dYSTNp9HCujoL8AwwR39NrI-N0UvQYqpO-G6W-1I6_OXAuVukQ08lbvopRKY2yVJlWWUJvj6gL5qyO8kI3FwsIuw4iSKC-s4RoTnZdVG8WevGFeuMdJ2Zl9cZF7yixAslaF4yKEx3rom3ZszmZBsyuq-9RAnx1XZac4keCI%3D&tracking_referrer=www.nature.com


Deep reinforcement learning
========================================================

![optional caption text](dqn2.png) 

http://icml.cc/2016/tutorials/AlphaGo-tutorial-slides.pdf




